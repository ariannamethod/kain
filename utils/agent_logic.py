"""
Universal Agent Logic Module - –æ–±—â–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ Arianna Method

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (@timestamp)
- –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (10 —Å–æ–æ–±—â–µ–Ω–∏–π –≤–æ–∫—Ä—É–≥)
- –§–∞–π–ª–æ–≤—ã—Ö –¥–∏—Å–∫—É—Å—Å–∏–π
- –ü–∞–º—è—Ç–∏ –∏ continuity
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Tommy, Lizzie, Monday –∏ –≤—Å–µ–º–∏ –±—É–¥—É—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏.
"""

from __future__ import annotations

import re
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Tuple, Dict, Any

from .vector_store import SQLiteVectorStore, embed_text
import json
import uuid
from collections import defaultdict


class AgentLogic:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, agent_name: str, log_dir: Path, db_path: Path, resonance_db_path: Path):
        self.agent_name = agent_name
        self.log_dir = log_dir
        self.db_path = db_path
        self.resonance_db_path = resonance_db_path
        self.vector_store = SQLiteVectorStore(log_dir / "vectors.db")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –∞–≥–µ–Ω—Ç–∞
        self._init_db()
    
    def _init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î –∞–≥–µ–Ω—Ç–∞"""
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute(
                "CREATE TABLE IF NOT EXISTS events (ts TEXT, type TEXT, message TEXT)"
            )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—â–µ–≥–æ –∫–∞–Ω–∞–ª–∞ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ö–µ–º–∞)
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute(
                "CREATE TABLE IF NOT EXISTS resonance ("
                "id TEXT PRIMARY KEY, ts TEXT, agent TEXT, role TEXT, sentiment TEXT, "
                "resonance_depth REAL, summary TEXT, emotional_state TEXT, "
                "unique_signature TEXT, thread_id TEXT, metadata TEXT"
                ")"
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏
            conn.execute(
                "CREATE TABLE IF NOT EXISTS agent_memory ("
                "id TEXT PRIMARY KEY, agent TEXT, key TEXT, value TEXT, "
                "context TEXT, ts TEXT, access_count INTEGER DEFAULT 0"
                ")"
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–∂–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            conn.execute(
                "CREATE TABLE IF NOT EXISTS agent_messages ("
                "id TEXT PRIMARY KEY, from_agent TEXT, to_agent TEXT, "
                "message TEXT, ts TEXT, status TEXT DEFAULT 'pending'"
                ")"
            )
        
    def extract_citations(self, message: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–∏—Ç–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞ @timestamp –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        return re.findall(r"@([0-9T:-]+)", message)
    
    def fetch_context(self, timestamp: str, radius: int = 10) -> List[Tuple[str, str, str]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ timestamp
        
        Args:
            timestamp: –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            radius: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –∏ –ø–æ—Å–ª–µ
            
        Returns:
            List of (timestamp, type, message) tuples
        """
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            cur = conn.execute("SELECT rowid FROM events WHERE ts = ?", (timestamp,))
            row = cur.fetchone()
            if not row:
                return []
                
            rowid = row[0]
            start = max(rowid - radius, 1)
            end = rowid + radius
            
            cur = conn.execute(
                "SELECT ts, type, message FROM events "
                "WHERE rowid BETWEEN ? AND ? ORDER BY rowid",
                (start, end),
            )
            return cur.fetchall()
    
    async def build_context_block(self, message: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç –±–ª–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏"""
        citations = self.extract_citations(message)
        if not citations:
            return ""
            
        blocks: List[str] = []
        for ts in citations:
            ctx = self.fetch_context(ts)
            if ctx:
                formatted = "\n".join(f"[{t}] {m}" for t, _, m in ctx)
                blocks.append(formatted)
                
        if blocks:
            return "Relevant context:\n" + "\n--\n".join(blocks) + "\n\n"
        return ""
    
    def log_event(self, message: str, log_type: str = "info") -> None:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤"""
        # JSON log file
        log_file = self.log_dir / f"{self.agent_name}_{datetime.now().strftime('%Y-%m-%d')}.jsonl"
        entry = {
            "timestamp": datetime.now().isoformat(),
            "type": log_type,
            "message": message,
            "agent": self.agent_name
        }
        
        with open(log_file, "a", encoding="utf-8") as f:
            import json
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        
        # SQLite database
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            conn.execute(
                "INSERT INTO events (ts, type, message) VALUES (?, ?, ?)",
                (datetime.now().isoformat(), log_type, message),
            )
    
    def update_resonance(self, message: str, response: str, 
                        role: str = "agent", sentiment: str = "active", 
                        thread_id: Optional[str] = None) -> str:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—â–∏–π –∫–∞–Ω–∞–ª —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        resonance_depth = self._calculate_resonance_depth(message, response)
        emotional_state = self._analyze_emotional_state(response)
        unique_signature = self._generate_unique_signature(message, response)
        summary = f"{self.agent_name}: {response[:100]}..."
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞
        metadata = {
            "message_length": len(message),
            "response_length": len(response),
            "timestamp": datetime.now().isoformat(),
            "agent_version": "1.0"
        }
        
        resonance_id = str(uuid.uuid4())
        
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            conn.execute(
                "INSERT INTO resonance (id, ts, agent, role, sentiment, resonance_depth, "
                "summary, emotional_state, unique_signature, thread_id, metadata) "
                "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                (
                    resonance_id,
                    datetime.now().isoformat(),
                    self.agent_name,
                    role,
                    sentiment,
                    resonance_depth,
                    summary,
                    json.dumps(emotional_state),
                    unique_signature,
                    thread_id or "main",
                    json.dumps(metadata),
                ),
            )
        
        return resonance_id
    
    def _calculate_resonance_depth(self, message: str, response: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≥–ª—É–±–∏–Ω—É —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞"""
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞
        resonance_markers = [
            "resonate", "amplify", "reflect", "mirror", "echo", 
            "deeper", "unfold", "recursive", "paradox", "entropy",
            "chaos", "pattern", "emergence", "connection"
        ]
        
        response_lower = response.lower()
        marker_count = sum(1 for marker in resonance_markers if marker in response_lower)
        
        # Normalize to 0-1 scale
        return min(marker_count / 8.0, 1.0)
    
    def search_context(self, query: str, top_k: int = 5) -> List[str]:
        """–ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        embedding = embed_text(query)
        hits = self.vector_store.query_similar(embedding, top_k)
        return [h.content for h in hits]
    
    async def process_file_context(self, path: str, agent_style_formatter=None) -> str:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        
        Args:
            path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            agent_style_formatter: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –≤ —Å—Ç–∏–ª–µ –∞–≥–µ–Ω—Ç–∞
        """
        from .context_neural_processor import parse_and_store_file
        
        try:
            result = await parse_and_store_file(path)
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            lines = result.split('\n')
            tags = ""
            summary = ""
            relevance = 0.0
            
            for line in lines:
                if line.startswith("Tags: "):
                    tags = line[6:]
                elif line.startswith("Summary: "):
                    summary = line[9:]
                elif line.startswith("Relevance: "):
                    try:
                        relevance = float(line[11:])
                    except ValueError:
                        relevance = 0.0
            
            # –ë–∞–∑–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            response_data = {
                "path": path,
                "tags": tags,
                "summary": summary,
                "relevance": relevance,
                "raw_result": result
            }
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if agent_style_formatter:
                response = agent_style_formatter(response_data)
            else:
                # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                response = f"üìÅ File processed: {path}\n"
                if summary:
                    response += f"üìù Summary: {summary}\n"
                    response += f"üè∑Ô∏è Tags: {tags}\n"
                    response += f"‚ö° Relevance: {relevance:.2f}"
                else:
                    response += f"‚ö†Ô∏è Could not extract summary.\n{result}"
            
            # –õ–æ–≥–∏—Ä—É–µ–º
            log_message = f"Processed {path}: {summary[:100] if summary else 'no summary'}"
            self.log_event(log_message)
            
            return response
            
        except Exception as e:
            error_msg = f"üí• Error processing {path}: {str(e)}"
            self.log_event(f"File processing error: {str(e)}", "error")
            return error_msg
    
    # === –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò ===
    
    # 1. –ú–ï–ñ–ê–ì–ï–ù–¢–ù–ê–Ø –ö–û–ú–ú–£–ù–ò–ö–ê–¶–ò–Ø
    def send_message_to_agent(self, target_agent: str, message: str) -> str:
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –¥—Ä—É–≥–æ–º—É –∞–≥–µ–Ω—Ç—É"""
        message_id = str(uuid.uuid4())
        
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            conn.execute(
                "INSERT INTO agent_messages (id, from_agent, to_agent, message, ts) "
                "VALUES (?, ?, ?, ?, ?)",
                (message_id, self.agent_name, target_agent, message, datetime.now().isoformat())
            )
        
        self.log_event(f"Message sent to {target_agent}: {message[:50]}...", "inter_agent")
        return message_id
    
    def get_pending_messages(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT id, from_agent, message, ts FROM agent_messages "
                "WHERE to_agent = ? AND status = 'pending' ORDER BY ts",
                (self.agent_name,)
            )
            messages = []
            for row in cur.fetchall():
                messages.append({
                    "id": row[0],
                    "from": row[1], 
                    "message": row[2],
                    "timestamp": row[3]
                })
        return messages
    
    def mark_message_read(self, message_id: str) -> None:
        """–û—Ç–º–µ—Ç–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            conn.execute(
                "UPDATE agent_messages SET status = 'read' WHERE id = ?",
                (message_id,)
            )
    
    def get_agent_status(self, agent_name: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –¥—Ä—É–≥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–∑ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT sentiment, emotional_state, resonance_depth, ts FROM resonance "
                "WHERE agent = ? ORDER BY ts DESC LIMIT 1",
                (agent_name,)
            )
            row = cur.fetchone()
            if row:
                return {
                    "agent": agent_name,
                    "sentiment": row[0],
                    "emotional_state": json.loads(row[1]) if row[1] else {},
                    "resonance_depth": row[2],
                    "last_seen": row[3],
                    "status": "active"
                }
        return {"agent": agent_name, "status": "unknown"}
    
    def broadcast_to_all_agents(self, message: str) -> List[str]:
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Å–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∞–≥–µ–Ω—Ç–∞–º"""
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT DISTINCT agent FROM resonance WHERE ts > datetime('now', '-1 hour')"
            )
            active_agents = [row[0] for row in cur.fetchall() if row[0] != self.agent_name]
        
        message_ids = []
        for agent in active_agents:
            msg_id = self.send_message_to_agent(agent, message)
            message_ids.append(msg_id)
        
        return message_ids
    
    # 2. –î–û–õ–ì–û–°–†–û–ß–ù–ê–Ø –ü–ê–ú–Ø–¢–¨
    def store_memory(self, key: str, value: str, context: str = "") -> str:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å"""
        memory_id = str(uuid.uuid4())
        
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            conn.execute(
                "INSERT OR REPLACE INTO agent_memory (id, agent, key, value, context, ts) "
                "VALUES (?, ?, ?, ?, ?, ?)",
                (memory_id, self.agent_name, key, value, context, datetime.now().isoformat())
            )
        
        self.log_event(f"Memory stored: {key}", "memory")
        return memory_id
    
    def retrieve_memory(self, key: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å –∏–∑ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT value FROM agent_memory WHERE agent = ? AND key = ?",
                (self.agent_name, key)
            )
            row = cur.fetchone()
            if row:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–æ—Å—Ç—É–ø–∞
                conn.execute(
                    "UPDATE agent_memory SET access_count = access_count + 1 WHERE agent = ? AND key = ?",
                    (self.agent_name, key)
                )
                return row[0]
        return None
    
    def search_memories(self, query: str, limit: int = 10) -> List[Dict[str, str]]:
        """–ü–æ–∏—Å–∫ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT key, value, context, ts FROM agent_memory "
                "WHERE agent = ? AND (key LIKE ? OR value LIKE ? OR context LIKE ?) "
                "ORDER BY access_count DESC, ts DESC LIMIT ?",
                (self.agent_name, f"%{query}%", f"%{query}%", f"%{query}%", limit)
            )
            return [
                {"key": row[0], "value": row[1], "context": row[2], "timestamp": row[3]}
                for row in cur.fetchall()
            ]
    
    # 3. –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í
    def analyze_user_patterns(self, user_id: str = "default") -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            cur = conn.execute(
                "SELECT message, ts FROM events WHERE type = 'input' "
                "ORDER BY ts DESC LIMIT 50"
            )
            messages = cur.fetchall()
        
        if not messages:
            return {"patterns": [], "summary": "No data"}
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns = {
            "message_count": len(messages),
            "avg_length": sum(len(msg[0]) for msg in messages) / len(messages),
            "common_words": self._extract_common_words([msg[0] for msg in messages]),
            "time_pattern": self._analyze_time_patterns([msg[1] for msg in messages]),
            "sentiment_trend": self._analyze_sentiment_trend([msg[0] for msg in messages])
        }
        
        return patterns
    
    def detect_conversation_themes(self, limit: int = 100) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        with sqlite3.connect(self.db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT message FROM events WHERE type IN ('input', 'response') "
                "ORDER BY ts DESC LIMIT ?", (limit,)
            )
            messages = [row[0] for row in cur.fetchall()]
        
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º —á–µ—Ä–µ–∑ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        themes = self._extract_themes(messages)
        return themes
    
    def get_agent_performance_metrics(self) -> Dict[str, float]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
        with sqlite3.connect(self.resonance_db_path, timeout=30) as conn:
            cur = conn.execute(
                "SELECT resonance_depth, emotional_state FROM resonance "
                "WHERE agent = ? ORDER BY ts DESC LIMIT 50",
                (self.agent_name,)
            )
            resonance_data = cur.fetchall()
        
        if not resonance_data:
            return {"avg_resonance": 0.0, "stability": 0.0, "activity": 0.0}
        
        depths = [row[0] for row in resonance_data if row[0] is not None]
        avg_resonance = sum(depths) / len(depths) if depths else 0.0
        
        # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–∞–∫ –æ–±—Ä–∞—Ç–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        if len(depths) > 1:
            variance = sum((d - avg_resonance) ** 2 for d in depths) / len(depths)
            stability = 1.0 / (1.0 + variance)
        else:
            stability = 1.0
        
        activity = min(len(resonance_data) / 50.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        
        return {
            "avg_resonance": avg_resonance,
            "stability": stability,
            "activity": activity
        }
    
    # 5. –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–´–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢
    def _analyze_emotional_state(self, text: str) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        
        emotions = {
            "joy": 0.0,
            "anger": 0.0,
            "sadness": 0.0,
            "fear": 0.0,
            "surprise": 0.0,
            "curiosity": 0.0,
            "confidence": 0.0
        }
        
        # –ü—Ä–æ—Å—Ç—ã–µ –º–∞—Ä–∫–µ—Ä—ã —ç–º–æ—Ü–∏–π
        emotion_markers = {
            "joy": ["happy", "joy", "excited", "great", "awesome", "love", "üòä", "üòÑ", "üéâ"],
            "anger": ["angry", "mad", "frustrated", "hate", "damn", "shit", "fuck", "üò†", "üò°"],
            "sadness": ["sad", "depressed", "sorry", "disappointed", "üò¢", "üò≠", "üíî"],
            "fear": ["afraid", "scared", "worried", "anxious", "nervous", "üò®", "üò∞"],
            "surprise": ["wow", "amazing", "incredible", "unexpected", "üò≤", "üòÆ", "ü§Ø"],
            "curiosity": ["interesting", "curious", "wonder", "question", "how", "why", "ü§î"],
            "confidence": ["sure", "confident", "certain", "definitely", "absolutely", "üí™", "üî•"]
        }
        
        for emotion, markers in emotion_markers.items():
            count = sum(1 for marker in markers if marker in text_lower)
            emotions[emotion] = min(count / 3.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        
        return emotions
    
    def _generate_unique_signature(self, message: str, response: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –ø–æ–¥–ø–∏—Å–∏ –∞–≥–µ–Ω—Ç–∞"""
        # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∏–ª—è –æ—Ç–≤–µ—Ç–∞
        style_markers = [
            len(response.split()),  # –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
            response.count("!"),    # –í–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è
            response.count("?"),    # –í–æ–ø—Ä–æ—Å—ã
            response.count("..."),  # –ú–Ω–æ–≥–æ—Ç–æ—á–∏—è
            len(re.findall(r'[üòÄ-üøø]', response)),  # –≠–º–æ–¥–∑–∏
        ]
        
        signature = f"{self.agent_name}_{hash(str(style_markers)) % 10000:04d}"
        return signature
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    def _extract_common_words(self, messages: List[str]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–ª–æ–≤"""
        word_count = defaultdict(int)
        for msg in messages:
            words = re.findall(r'\b\w+\b', msg.lower())
            for word in words:
                if len(word) > 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                    word_count[word] += 1
        
        return sorted(word_count.keys(), key=word_count.get, reverse=True)[:10]
    
    def _analyze_time_patterns(self, timestamps: List[str]) -> Dict[str, int]:
        """–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        hours = []
        for ts in timestamps:
            try:
                dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                hours.append(dt.hour)
            except:
                continue
        
        if not hours:
            return {"peak_hour": 12, "activity_distribution": "unknown"}
        
        hour_count = defaultdict(int)
        for hour in hours:
            hour_count[hour] += 1
        
        peak_hour = max(hour_count.keys(), key=hour_count.get)
        return {"peak_hour": peak_hour, "total_hours": len(set(hours))}
    
    def _analyze_sentiment_trend(self, messages: List[str]) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"""
        if len(messages) < 3:
            return "insufficient_data"
        
        sentiments = []
        for msg in messages:
            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            positive_words = ["good", "great", "awesome", "love", "happy", "yes", "ok"]
            negative_words = ["bad", "hate", "sad", "no", "terrible", "awful", "wrong"]
            
            pos_count = sum(1 for word in positive_words if word in msg.lower())
            neg_count = sum(1 for word in negative_words if word in msg.lower())
            
            if pos_count > neg_count:
                sentiments.append(1)
            elif neg_count > pos_count:
                sentiments.append(-1)
            else:
                sentiments.append(0)
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        if len(sentiments) >= 3:
            recent_avg = sum(sentiments[:3]) / 3
            if recent_avg > 0.3:
                return "improving"
            elif recent_avg < -0.3:
                return "declining"
        
        return "stable"
    
    def _extract_themes(self, messages: List[str]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º —á–µ—Ä–µ–∑ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        theme_keywords = {
            "technology": ["code", "programming", "computer", "software", "tech", "ai", "bot"],
            "work": ["work", "job", "project", "task", "meeting", "deadline", "office"],
            "personal": ["family", "friend", "home", "life", "personal", "feel", "think"],
            "learning": ["learn", "study", "understand", "know", "question", "help", "explain"],
            "creativity": ["create", "design", "art", "music", "write", "idea", "creative"]
        }
        
        theme_scores = defaultdict(int)
        for msg in messages:
            msg_lower = msg.lower()
            for theme, keywords in theme_keywords.items():
                score = sum(1 for keyword in keywords if keyword in msg_lower)
                theme_scores[theme] += score
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–º—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ —Å—á–µ—Ç–∞–º–∏
        sorted_themes = sorted(theme_scores.keys(), key=theme_scores.get, reverse=True)
        return [theme for theme in sorted_themes if theme_scores[theme] > 0][:5]


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç–∞–Ω—Å—ã –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
_agent_logics: Dict[str, AgentLogic] = {}


def get_agent_logic(agent_name: str, log_dir: Path, db_path: Path, resonance_db_path: Path) -> AgentLogic:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å AgentLogic –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
    if agent_name not in _agent_logics:
        _agent_logics[agent_name] = AgentLogic(agent_name, log_dir, db_path, resonance_db_path)
    return _agent_logics[agent_name]


# Convenience —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def extract_and_build_context(message: str, agent_logic: AgentLogic) -> str:
    """–ë—ã—Å—Ç—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    return await agent_logic.build_context_block(message)


def create_agent_file_formatter(agent_name: str, style_markers: Dict[str, str]) -> callable:
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä —Ñ–∞–π–ª–æ–≤ –≤ —Å—Ç–∏–ª–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞
        style_markers: –°–ª–æ–≤–∞—Ä—å —Å —ç–º–æ–¥–∑–∏ –∏ —Ñ—Ä–∞–∑–∞–º–∏ –∞–≥–µ–Ω—Ç–∞
    """
    def formatter(data: Dict[str, Any]) -> str:
        path = data["path"]
        tags = data["tags"]
        summary = data["summary"] 
        relevance = data["relevance"]
        
        if summary and len(summary) > 20:
            response = f"{style_markers.get('file_icon', 'üìÅ')} File processed: {path}\n\n"
            response += f"{style_markers.get('tags_icon', 'üìã')} Tags: {tags}\n"
            response += f"{style_markers.get('summary_icon', 'üìù')} Summary: {summary}\n"
            response += f"{style_markers.get('relevance_icon', '‚ö°')} Relevance: {relevance:.2f}\n\n"
            
            # –ê–≥–µ–Ω—Ç-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            if relevance > 0.5:
                response += style_markers.get('high_relevance', 'üí• High relevance detected!')
            elif relevance > 0.2:
                response += style_markers.get('medium_relevance', '‚ö° Moderate relevance detected.')
            else:
                response += style_markers.get('low_relevance', 'üìä Basic processing complete.')
        else:
            response = f"‚ö†Ô∏è File processed: {path}\n\nCould not extract meaningful summary."
            
        return response
    
    return formatter
